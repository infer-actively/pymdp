{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# T-Maze Task\n",
    "\n",
    "In this notebook, we simulate a T-Maze task (also known as the three-arm bandit task) using an active inference (AIF) agent with the `jax-pymdp` library. The `jax-pymdp` package is a newer, enhanced version of the original [`pymdp` package](https://pymdp-rtd.readthedocs.io/en/latest/) that allows for scaling up active inference agents. Built on JAX, `jax-pymdp` allows for faster computation and simulation of active inference models, and the ability to scale models to run multiple agents simultaneously through batching, making it ideal for complex, multi-agent tasks.\n",
    "\n",
    "The T-Maze task we use in this notebook is adapted from [the sophisticated inference paper](https://discovery.ucl.ac.uk/id/eprint/10124606/). This task represents a classic problem in spatial navigation, learning, and decision-making, where an agent (in this case, a rat) must navigate a T-shaped maze. The agent starts at the centre of the T-maze. Within either the left or right arm, there is either a preferred (i.e., rewarding; cheese) stimulus or an aversive (i.e., punishing; shock) stimulus, with their locations initially unknown to the agent. In the bottom arm, an instructional cue provides information about the location of the rewarding stimulus.\n",
    "\n",
    "To solve the maze and locate the reward, the agent must decide whether to commit to one of the potentially rewarding arms or first seek information from the cue to identify the more profitable option before taking action. Cue validity, set at 95% in this simulation, represents the probability that the cue correctly indicates the reward's location. An optimal agent should learn to exploit the cue when it is valid and explore the arms when it is not. \n",
    "\n",
    "In this notebook, we will create the following simulations: \n",
    "1. single agent solving the task with vanilla active inference\n",
    "2. single agent solving the task with sophisticated inference\n",
    "3. multiple agents solving the task with vanilla active inference\n",
    "4. multiple agents solving the task with sophisticated inference"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Initial Setup\n",
    "To run this notebook, it is recommended to set up and use a virtual environment. You can refer to [this guide](https://packaging.python.org/en/latest/guides/installing-using-pip-and-virtual-environments/) to learn how to set up a virtual environment.\n",
    "\n",
    "Then, install the current repo, with the `jax-pymdp` package, as a package in editable mode by running the following command in your terminal:\n",
    "```bash\n",
    "pip install -e .\n",
    "```\n",
    "\n",
    "You also need to install [JAX](https://jax.readthedocs.io/en/latest/installation.html) to run this notebook."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The autoreload extension is already loaded. To reload it, use:\n",
      "  %reload_ext autoreload\n"
     ]
    }
   ],
   "source": [
    "# a way to edit and run code and see the effects in the notebook without having to restart the kernel\n",
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "\n",
    "# importing necessary libraries\n",
    "import jax.numpy as jnp\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "\n",
    "from jax import random as jr\n",
    "from pymdp.envs import TMaze\n",
    "from matplotlib.animation import FuncAnimation, PillowWriter\n",
    "from IPython.display import HTML\n",
    "from pymdp.agent import Agent\n",
    "from pymdp.envs.tmaze import aif_loop"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### The T-Maze Environment\n",
    "\n",
    "The environment can run multiple instances in parallel by adjusting the `batch_size` parameter.\n",
    "\n",
    "#### States and Observations\n",
    "\n",
    "**State Factors:**\n",
    "1. Location (5 states):\n",
    "    - 0: centre (start location)\n",
    "    - 1: left arm\n",
    "    - 2: right arm\n",
    "    - 3: cue location (bottom arm)\n",
    "    - 4: middle of arms (between left and right arm)\n",
    "2. Reward Location (2 states):\n",
    "    - 0: reward in left arm \n",
    "    - 1: reward in right arm\n",
    "\n",
    "**Observation Modalities:**\n",
    "1. Location (5 observations):\n",
    "    - Matches the location states exactly\n",
    "2. Outcome (3 observations):\n",
    "    - 0: no outcome\n",
    "    - 1: reward (cheese)\n",
    "    - 2: punishment (shock)\n",
    "3. Cue (3 observations):\n",
    "    - 0: no cue\n",
    "    - 1: left arm cued\n",
    "    - 2: right arm cued\n",
    "\n",
    "#### Environment Parameters\n",
    "\n",
    "**Observation Likelihood Model (A):**\n",
    "- A[0]: Location observations (5x5x1 tensor)\n",
    "  - Perfect mapping between true and observed location\n",
    "- A[1]: Outcome observations (3x5x2 tensor)\n",
    "  - In correct arm, the `reward_probability` is set at 100% \n",
    "  - In incorrect arm, the `punishment_probability` is set at 100%\n",
    "  - No outcomes in centre or cue locations\n",
    "- A[2]: Cue observations (3x5x2 tensor)\n",
    "  - Cue indicates reward location only at cue location, with `cue_validity` set at 95%\n",
    "  - No cues visible elsewhere\n",
    "\n",
    "**Transition Model (B):**\n",
    "- B[0]: Location transitions (5x5x4 tensor)\n",
    "  - Agent can move between any locations in one step \n",
    "- B[1]: Reward location (2x2x1 tensor)\n",
    "  - Reward location remains fixed throughout trial\n",
    "\n",
    "**Initial Conditions (D):**\n",
    "- D[0]: Starting location (5x1 tensor)\n",
    "  - Agent always begins in centre location\n",
    "- D[1]: Reward placement (2x1 tensor)\n",
    "  - Default: Equal chance (50/50) of reward in either arm (reward_condition=None)\n",
    "  - Optional: Can fix reward to specific arm, by setting `reward_condition` to 0 (for left arm) or 1 (for right arm)  \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "batch_size = 1 # number of environments to run in parallel\n",
    "env = TMaze( # initialising the environment\n",
    "    batch_size=batch_size, \n",
    "    reward_probability=1.0,     # 100% chance of reward in correct arm\n",
    "    punishment_probability=1.0, # 100% chance of punishment in incorrect arm\n",
    "    cue_validity=1.0,          # 95% valid cues\n",
    "    reward_condition=1\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[1. 1. 1. 0. 1.]\n",
      " [0. 0. 0. 0. 0.]\n",
      " [0. 0. 0. 1. 0.]]\n",
      "[[1. 0. 0. 0. 0.]]\n",
      "[[0. 1.]]\n"
     ]
    }
   ],
   "source": [
    "# print(env.params[\"A\"][1].shape)\n",
    "# print(env.params[\"A\"][1][0][:,:,1])\n",
    "\n",
    "# print(env.params[\"A\"][2].shape)\n",
    "print(env.params[\"A\"][2][0][:,:,1])\n",
    "\n",
    "# print(env.params[\"B\"][0].shape)\n",
    "# print(env.params[\"B\"][0][0][:,:,4])\n",
    "\n",
    "print(env.params[\"D\"][0])\n",
    "print(env.params[\"D\"][1])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "key = jr.PRNGKey(1) # random key for generating random numbers\n",
    "keys = jr.split(key, 1 + batch_size) # splitting the key into 1 + batch_size keys\n",
    "key = keys[0] # saving the first key for later use\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Creating the Agent"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Riddhi's notes: \n",
    "- to try A learning with A[1] - the agent can learn the probability of reward in the correct arm and the probability of punishment in the incorrect arm.\n",
    "- to try A learning with A[2] - the agent can learn the cue validity.\n",
    "- apply_batch?? \n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "A = [jnp.array(a, dtype=jnp.float32) for a in env.params[\"A\"]]\n",
    "B = [jnp.array(b, dtype=jnp.float32) for b in env.params[\"B\"]]\n",
    "A_dependencies = env.dependencies[\"A\"]\n",
    "B_dependencies = env.dependencies[\"B\"]\n",
    "\n",
    "# create C tensors [location], [reward], [cue] based on A shapes\n",
    "C = [jnp.zeros((batch_size, a.shape[1]), dtype=jnp.float32) for a in A] \n",
    "# set preferences for outcomes only (keeping other preferences at zero)\n",
    "C[1] = C[1].at[:,1].set(2.0)    # prefer reward - note the [:,1]\n",
    "C[1] = C[1].at[:,2].set(-3.0)   # avoid punishment - note the [:,2]\n",
    "# C = [jnp.broadcast_to(c, (batch_size,) + c.shape) for c in C]\n",
    "\n",
    "\n",
    "# create D tensors [location], [reward] based on B shapes\n",
    "D = []\n",
    "# D[0]: location - all zeros except location 0 (centre) because the agent always starts in the centre\n",
    "D_loc = jnp.zeros((batch_size, B[0].shape[1]), dtype=jnp.float32) \n",
    "D_loc = D_loc.at[0,0].set(1.0)  # set centre location to 1.0\n",
    "D.append(D_loc)\n",
    "\n",
    "# D[1]: reward location - uniform distribution\n",
    "D_reward = jnp.ones((batch_size, B[1].shape[1]), dtype=jnp.float32) \n",
    "D_reward = D_reward / jnp.sum(D_reward, axis=1, keepdims=True)  # normalise to get uniform distribution\n",
    "D.append(D_reward)\n",
    "\n",
    "\n",
    "agent = Agent(\n",
    "    A, B, C, D, \n",
    "    None, None, None, \n",
    "    policy_len=6,\n",
    "    A_dependencies=A_dependencies, \n",
    "    B_dependencies=B_dependencies,\n",
    "    apply_batch=False\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[1. 0. 0. 0. 0.]]\n",
      "[[0.5 0.5]]\n"
     ]
    }
   ],
   "source": [
    "# print([a.shape for a in A])\n",
    "# print([b.shape for b in B])\n",
    "# print([c.shape for c in C])\n",
    "# print([d.shape for d in D])\n",
    "\n",
    "# print(agent.A_dependencies)\n",
    "# print(agent.B_dependencies)\n",
    "\n",
    "# print(agent.A[0][:,:])\n",
    "# print(agent.A[1][0][:,:,0])\n",
    "# print(agent.A[2][0][:,:,1])\n",
    "\n",
    "\n",
    "# print(agent.B[0][0][:,:,0])\n",
    "# print(agent.B[1][0][:,:,0])\n",
    "\n",
    "# print(agent.C[0])\n",
    "\n",
    "print(agent.D[0])\n",
    "print(agent.D[1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "key = jr.PRNGKey(0)\n",
    "T = 10\n",
    "_, info, _ = aif_loop(agent, env, num_timesteps=T, rng_key=key)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[[1.]\n",
      "  [0.]\n",
      "  [0.]\n",
      "  [0.]\n",
      "  [0.]\n",
      "  [0.]\n",
      "  [0.]\n",
      "  [0.]\n",
      "  [0.]\n",
      "  [0.]]]\n"
     ]
    }
   ],
   "source": [
    "# print(info[\"action\"][0])\n",
    "print(info[\"observation\"][2])\n",
    "# print(info[\"qs\"][1])\n",
    "# print(info[\"qpi\"][0].shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAZQAAAGVCAYAAADZmQcFAAAAOXRFWHRTb2Z0d2FyZQBNYXRwbG90bGliIHZlcnNpb24zLjkuMiwgaHR0cHM6Ly9tYXRwbG90bGliLm9yZy8hTgPZAAAACXBIWXMAAA9hAAAPYQGoP6dpAAAlp0lEQVR4nO3deXSddYH/8c9z9yX71qRJ0y1pSUtpAyKFAgWkMBSsoIACw2oH9afwG3UOwwCKdRTR444DjmzO/FBwxBEBGRkQEVCWUpBuhG40afY0e3L3e5/fH2mjpYWW9tve5ybv1zmcQ3Nvnvu9Oel99/t8n8WybdsWAACHyJXtAQAAJgaCAgAwgqAAAIwgKAAAIwgKAMAIggIAMIKgAACMICgAACMICgDACIICADCCoAAAjCAoAAAjCAoAwAiCAgAwgqAAAIwgKAAAIwgKAMAIggIAMMJjdGu9W6WWF41uEs6zLT5Lm+Nzsj0MHGZF7rQKXOlsDwOH2dS6IhVWhIxsy2xQWl6UfvNZo5uE87zS9wnd23tttoeBw2y+P6p6XyLbw8Bh9qGrGowFhV1eAAAjCAoAwAiCAgAwgqAAAIwgKAAAIwgKAMAIggIAMIKgAACMICgAACMICgDACIICADCCoAAAjCAoAAAjCAoAwAiCAgAwgqAAAIwgKAAAIwgKAMAIggIAMIKgAACMICgAACMICgDACIICADCCoAAAjCAoAAAjCAoAwAiCAgAwgqAAAIwgKAAAIwgKAMAIggIAMIKgAACMICgAACMICgDACIICADCCoAAAjCAoAAAjCAoAwAiCAgAwgqAAAIwgKAAAIwgKAMAIggIAMIKgAACMICgAACMICgDACIICADCCoAAAjCAoAAAjCAoAwAiCAgAwgqAAAIwgKAAAIwgKAMAIggIAMIKgAACMICgAACMICgDACIICADCCoAAAjCAoAAAjCAoAwAiCAgAwgqAAAIwgKAAAIwgKAMAIggIAMIKgAACMICgAACMICgDACIICADCCoAAAjCAoAAAjCAoAwAiCAgAwgqAAAIwgKAAAIwgKAMAIggIAMIKgAACMICgAACMICgDACIICADCCoAAAjCAoAAAjCAoAwAiCAgAwgqAAAIwgKAAAIwgKAMAIggIAMIKgAACMICgAACMICgDACIICADCCoAAAjCAoAAAjCAoAwAiCAgAwgqAAAIwgKAAAIwgKAMAIggIAMIKgAACMICgAACMICgDACIICADCCoAAAjCAoAAAjCAoAwAiCAgAwgqAAAIwgKAAAIwgKAMAIggIAMIKgAACMICgAACMICgDACIICADCCoAAAjPAY3dqU+dKSfzS6STjQujqpN9uDwOFWPadYjXP82R4GDrOSqXnGtmU2KFMbx/7DxBbrlNa0ZXsUOMxmLCjVSedWZnsYyCHs8gIAGEFQAABGEBQAgBEEBQBgBEEBABhBUAAARhAUAIARBAUAYARBAQAYQVAAAEYQFACAEQQFAGAEQQEAGEFQAABGEBQAgBEEBQBgBEEBABhBUAAARhAUAIARBAUAYARBAQAYQVAAAEYQFACAEQQFAGAEQcGEMNTXpNX/+0mlEiOH7TWGBzZr9ZNXKxkfPGyvAeQygoIJwecvkuVyy7bTh+010qmovIESudy+w/YaQC7zZHsAgAmBcKXyCmcrMtKqQn/huz7PtjMa6t24V3jcnqDyi+e8x/fZig7tUGnVCXJ7gsbGDUwkBAU5KZNJyZIly+Ue/1p5zWna8daDKjjxq7KsPSfftm1rdHCr2jb/l2IDf9Zxxy1SKBTata2M/vTiXxQsOkEz5q+U11+4j+9Pq2P7E5pz7Of3Ow5gsmKXF3LS9o0/1YaXV+2xZlJccayS8UE1b/xP2XZm/OupxIh6Wp9V51vf1IeWFOi66/6Pli9fruLiYlVWVmrFihX6x+v/Qcc2xNW27ovatu4nymRS49+fTsW06bXvKlQwXXlFdeNfj4126o0/fl5dO35/ZN404HAEBTlp+lF/L5fLp02vf0+p5KhsOyOX26uGE27RwM61Guh5Q5lMSul0XJtf/44C8V/qI+edqiVLlmjhwoVavXq17rvvPt1///1qbW1VY2OjzjzzTF30seXyp/6slqYHlMmklEkntLP9z7LtjOoWfk7S2GwlHuvVhpe+ouIpx2tK7bIs/zQAZ2CXF3KS2xPQUcffqLfX36MNL35FlTPO1pTaMxUITdH8xbdq3Z9uUkHpfEVHWhUfXK1pi87Q/fffr7y8PK1cuVI/+9nPxtZFolHddddduvHGG7Vq1SqFQiEdd9xxeuKJu5WIDygZ65fLHdDc474ol9sn286o5a2HNNzbpCm1Z6m67iOyLCvbPw7AEZihIGe5XB7NWvAp1S+6Tq2bfqm1z9+g0cG3lU5FNfuYT6u75WkVBZq1YsWH1dHRIZ/Pp4svvlg+n0+ZzF93iXV0dKi0tFTLli3TyMiIXC6XPvvZz+jomX1KRLtVM+dCJWJ96ut6VWuf/2cNdP9F9Y3Xq7ruAlkWayfAbsxQkFNs25ak8VmBZVkK5k/TsR+6S907nlH724+rp/WPigy1SMrorbekadOmaWhoSCtXrtTHPvYxbd68WZdffvke262oqNAXvvAFSVJbW5taW1v16quvyuVy6+UnLlNR+UIVlh2j6UddpsLyY/axaJ+RbdtysTiPSYygIKe0bvov9Xa8qMqZy1Vccaz8wbJdcbE0pfZMlVYu1kh/k+bOLtaCBQvU3t6unp4ehUIhNTQ0yLIszZkzR3Pm7H2IsG3bWrBggVpbW9Xf36/LLrtMZWVlevTRR5Vw12n2MZ/a6xyU6Eibulp+r6He9aqcuVwVNacdmR8E4EAEBTmlZs7FKqo4Vl3NT2rHWw+puOK4XY+MzVxGh5o1tPM1RQpmqa2tTQ0NDbriiivGY/JeLMvS2WefrbPOOkurV6/Whg0b9NxzzykYDOrtjQ/LttPy+PJlaSxgkrSz40+aUnum5n7gn+ULlBzGdw44n2Xv3ocAHKCHHuvUvQ+1ZXUMdiatWLRbsqXoaJs6tj2m6Ei7qsoSuvLKy9XQ0KDi4mIFg8GDXjS3bVvDw8MaHR1VT0+Pvv3tb6ulPaWiikWqmnmufP4SWS6X/MGKCbkwf+2l1bro3MpsDwM5hBkKcpLlcisYrpI0dpa8z1+sppdv0bJl52jJkiUKBg/9bHbLslRQUKCCggJVVlbq0ksv1Xfv+LVmL/iUvO9xNj4wWXGUFyYAW83rv6MLVpysU0891UhM9uWkk07SWafXa8vr3z4s2wdyHTMU5DTbzqjj7d+qtDCls88+W7W1tXs83tTUpJ///OeKxWL6/Oc/r6qqqvfcXjKZ1IMPPqh169YpPz9fN998s9xu9/hsZeXKlXrhz9ept+NFlVQunpC7uoCDRVCQ0+LRHmVG/qhPXn2ZZs2aJZfrr5PuVCqlp59+Wk888YQkKRqN6o477njP7a1Zs0Y/+tGPlMlkFA6H9eEPf1iNjY3jjxcWFuozn/p73fFv31NR+X9woUjgb7DLCzlt2xt36Jh5FTrmmGP2iIkkDQ4O6tlnn1V9fb0+/vGPK5lM7nFC475kMhn5/X594Qtf0OjoqH7/+z2v02VZls444wx94Nij1dL0wB7XDAMmO4KCnGTbtgZ3rpNXrbr44otVVFS013NKSkq0fPlyjYyMqL29XZZlHdAuqnQ6ra1btyoYDGrx4sV7Pe71enXVVVcoPbpGkaFmE28HmBAICnJSJpNQx9uP68PnnqapU6fuMxSWZemCCy5QXV2denp6dP311+83KIsWLdL555+vpqYm3XjjjVqyZMk+n1dbW6tLP36Wtrx++2G9qReQS1hDQc6xbVsd2x5XyFqv449fIa/X+67PLS4u1ve+970D3nYoFNINN9yw3+e5XC6dddZZ+p/fPaOe1udVXnPqXpdjASYb/gYgp4wMbNHb6+/Rjjd/rIqKcj377LNZG8uWLVsUCroV6/4Pvfb0SvV1vqJ0Kp618QDZxgwFOSGdimrb2jsVH/6LrrnyApWU3KylS5dm9bDdRYsW6Qc/+IHa2tq0du1aPfPML7V5zWMqr13OIcWYlAgKHC8RG1DT6q9pxd/V6+8vu0vhcNhRH9bV1dWqrq7WGWecoa1bt+pLX/6aJKm06sQsjww4stjlBUdLJSPa/NrtOmtpja65+mrl5eU5KiZ/y+/3a968efrav35J3Vv+Tb3tL4pL5WEyIShwLNvOaPvGn2r5h6bruuuuk8/n2/83OcBRRx2l22+7WX3bf6T+rtXZHg5wxBAUONZQ70aV5zXrkksukdudOzeusixLDQ0N+uqqm9Td8lulU7FsDwk4IggKHGv7+jv0d2edpMLC3Lyy7+zZs1VXM6rB3vXZHgpwRBAUOFI82qvSkrCWLl2as+sQfr9fJ598sqIjbTn7HoD3g6DAkbqan1Qi0qqBgQHF44d+bodt20qn0/v9YLdte7/X+zoQkUhEbW1t8nq9annzfu2+oyQwkREUONbnPve58bsmHqpMJqNbbrlFbW3vfqdJ27a1Zs0a/eEPfzik17JtWz09PWpubtbpp5+uo+fPP6TtAbmCoMCxysrKJEmbN29Wb2/vIe82Wrt2rf7yl7+853Oam5sVix3aInoqldKOHTtk27b8fr88Xk73wuRAUOBYmzdvljR206sNGzaor6/vkLZXVVWlurq693zOlClTDnr7tm0rEonozTffVCqV+psHDnqTQE4hKHAkl9uvhx/+7/E/ZzIZNTU1aefOnXt+WO9HOp1WMpmUJNXU1Gju3Lnv+lzLssbvqZJOp9/XWkoymVR7e7vWr18/Hr6amhq9/PLL2rxlywFvB8hlzMXhSJXTz9bOLa+qoKBAbrd7PAzr169XQUGBqqqqVFlZ+a5nze9ex+jq6lJ+fr76+voUiUQO6Cz7l156SQsXLlQkElEoFFJFRcW7nlSZTqfV0dGhjo4OjY6O7vFYOBxWd3e3vOF5kpx5dj9gEkGBI3l8eeofsvXCCy+otrZWg4OD448NDQ1peHhY7e3t41/z+Xzy+XwaGRkZ/9rugEybNk0PPPCAPvGJT+z3dRcsWKBHHnlE8Xh8/MZc7e3t4ydWhsNhSRqPh23be7zmbkVFRfJ6vXroF49o6qx/cuzlYgCT2OUFx6pt+JSe+J//UXV1tfLz8/d4bPfRX7v/6+3tVUdHxx5fsyxL8+bNU2dnp7q6ujRnzpz9vmZ+fr6WLVumBx54QJWVlZLGwrR7m52dners7Bz/875iYlmWqqqq9PzzzythzVFBKUd5YXIgKHCsYF6Ndo42aMvWbSovL39f/8q3LEslJSVKpVL64Q9/qOXLlysvL++AvveUU05RS0uLVq9erbq6ur3uVf9e3G636uvrFQgE9Lv/fVbTGq5mdoJJg6DAsVxur6bOPl+3f/MOdXV1qb6+/oCi4Ha7NWfOHJWWluqmm27SKaeconPOOeeAXzcQCOjLX/6yfv3rX2vDhg2aNWvWAUXBsizV1dWptLRUt932DbX3VsofLD/g1wVyHUGBo4Xya5XOuHXPPfdo/fr1qqqqUllZ2T4XycPhsEpKSjR/14mEX/nKV3T22Wfroosuet+vO336dH3jG9/Qgw8+qDVr1mjx4sWqrKyU3+/f67mBQEBVVVU68cQTtWPHDt166616oymm+sb/K5eLZUpMHvy2w/Fmzpypf7nhWj366KN67LHHtGTJEp166qlKJpPy+/1yuVxKp9PyeDwKBoP61a9+pZdeekknn3yyLrzwwoPe5VRVVaVVq1bp9ttv12uvvaarrrpKM2bMUCKRUDAYlDR2EqPL5VI0GtXXv/51dXR06Pzzz9fmlpfkcufG5fYBUwgKHC8ajSocDuvaa6/V8PCwfvzjH+uVV15RZ2enPvKRjygUCqmlpUW/+MUvtGzZMgUCAX3rW99SKBQ65PWL6dOn6/vf/76ee+45PfTQQ9qwYYPcbrcuvPBCSdKmTZv03HPPqbGxUUuXLtWSJUvU19cn94PcBwWTD0GB421vbtaLL76oc845R0VFRbrxxhvV39+vTZs2jT+noqJCH/zgB9XY2CiPx+yvtd/v17Jly7Rs2TJt375dXV1de7zuOeeco7q6uvHdcI888she56QAkwFBgeMVlB2/1wd0cXGxTjjhhCM+lhkzZmjGjBnv+ZyBgUEVT/ngkRkQ4CAsysPRLMvSlNpl2rlzp9LpdLaHs1/RaFTDIxFV1J6Z7aEARxxBgeNZlkv/+f9+rqGhoWwPZb/efPNNPf3U09keBpAVBAWOl188VxXTzlRzc3O2h/KebNtWc3OzZi5YKa+vINvDAY44ggLHc7l9qqhdrgd+9l9G7qZ4uGQyGT30y6dVXnOaLIu/Wph8+K1HTigqX6i3m3u0cePGbA/lXb322mtKZsIKF8zM9lCArCAoyAmWyy1/8Rm6976fjt/fxEn6+/t1773/oaKp53LtLkxaBAU5wbJcqq77qN5u8+r111/P9nD28vTTT6traJrKqk7M9lCArCEoyBlut19Vsy/TI7/5reLxeLaHM250dFS//d2Lqm24gsutYFIjKMgpecX1WtuU0p133umIBfrR0VHdcsstimQaFAhVZns4QFYRFOQUt9uvuR+4QX/4c4/uvPNOxWKxrI1laGhIX/vabdrRO0vTGy5n7QSTHkFBzvH6CzXnAzfr8ae26u6775Zt20d8DLFYTKtWfVVv7SjT7IWfldsTMLZt287ItjPKZFLq7XhRW9f+u2KR7l1fP/LvFThQXMsLOcnjDevok/5VTz13m9LpH+gzn/nMPu9VcjgMDAzoG7d/Uy29szR74SeNnXNi27aG+jaofctvlBzdoPo59fIlRlQaiCizs0UDibS6B8tUt/CzcnuCRl4TMImgIGd5vHmqP/ZGPfnsKvn89+maq6+W3+8/bLueMpmMotGobrvtdm1uK1d947VGbqBlZ9KKR3vU8ub98maadPUlF6i4+GQde+yxuuuuf1cyNbZWNDIyrK72F9S+OU9T51wjNwcAwGHY5YWc5vUX6OiTvqanXxjWxZd8Wq+88spheR3btvXwww/rksu/qObeetUvut5ITNKpqDa99l31bfmSrvrEfN13751qaGjQr/77UV25cpVe3zxFfa5Pq8/1aQ17r9ZQJKiR7ifVse1xA+8KMIsZCnKe2xPUnONu0GDvBn3rOz/S/KN+p+uv/6zC4bACgcBBz1hs21YkElFHR4d+cvf92rhpULMbv6RgXvUhj9m2bfV1vqSdLY9o6YlTdeGFt6qkpER33PFvWvP6mwpN+YRmLjpBXn/h+Pd4fQWaf+I3NDq0XXnFdYc8BsA0goIJo6BknvKP/6G2bfuNrvjkrZo1zdJpp52mZcuWqbCwcP8b+BstLS3605/+pCeeeEKDsWkqn3a25i05SS6X95DHGY/2qnvHM+rf8aCuv+5anXnmmfrjH/+oJ59+Tc1dxZpx3I9lubz7DGG4cIbChTMOeQzA4UBQMGFYliXL7VVN/YUqrzld0ZEdevDR5/W7p74un9dSaUlAl116ifLy8vb5/X19fbrn3vuVzgQ1MDgihU5Rfs0XNaWoXh5v2MgYE7F+vfXKrTpuYanO+Ph1OvHEE/X444/r7p/+VrMW3aIZ86dxYUnkLIKCCckfLJU/WKrCsoWSbEVH2vRW85O65ban5Em8rKVLl0iS0um0enp61NPTo9WrX9XMo/9B1XUXqGZGiSTL2AK/bdtKxvu17oUbdfIJ1froRz+qUCike+65T08+26q6Y1cpEK7iXBbkNIKCCW3sA9pSKH+aZh29Uul0XBtfeEM1NTU677zzJEmtra3atGmT8vLytXHbNrlcXqOzhEw6qe0bfyrF1ujMpbO1YsUK+f1+/ctNX1Wg/OOae/yVxmZAQDYxt8ak4nb7NavxS7r3p48rkUjIsizV1NRo9uzZOuecv9Oc2rg2vvxVpVOxQz6J0LZt2Zm0Wpp+JnfsGV1z5fm65JJLFAgEdPPNX1ZoymWqmnkOMcGEQVAw6YQLpitcfrq+/vXbNDw8LMuyVFtbq9mzZ+vcc8/Voga/2t/8lvo6X5ZtH/z1wgZ3rtP6565UgftlXXvttVq8eLHS6bRuvOmr8ldcoYraDxl8V0D2scsLk9LU2RfojVe36tvf/q5uuOGfFAwGNW3aNAUCAZWUlKipqUm/+tX31d95vKbWXaxAuOqAzjux7bRSyYi2rbtT0f7XddHHlqmhoUENDQ0aHBzUv9z0JQXLL1fl9LOOwLsEjiyCgklp90Umt2x5WBdfer0+8w8X6LzzzlNFRYWKi4sVDAZVVVWldevW66nf/5Os4CJV1Jyu0qrF77rN4f5N2tn2vFJDf9CC+bN18pJrVF1drfLycv3kJz/R6jeGVFB5jcprTjtybxQ4gggKJi2X26tpcy9R6dQl+vE9/6pYPKUzP3SaioqKNHfuXE2dOlXV1dWqrp6qzs5OPfX7H6q/7XGl0ilFo1FZsjS2ymIrHAopNtqqM5YuVH39RZoxY4ZqamokSXffc6/+vCamOcfdxHoJJjTL5vKleJ8eeqxT9z7Ulu1hGGPbttKpqLp3/K9S/Y/oYx/9sFasWCGPZ+zfW4lEQi0tLYpGo+ru7lZXV9del3g59dRTVVtbq8LCQlVUVGhkZETPPPOMfvaLp1RYsUQz5q80cqmWI+naS6t10bnc4wUHjqDgfZtoQdnNtm0N9zepbcvDKi/o03nLl6qxsVHl5eUKBoNKp9OKRCLv+v2JREKRSESPPvaYXnrlLWX8i1VWfapC+TVH8F2YQ1DwfuXWP5mAw8iyLBWUNCj/+Fs0MrBFP//NH3TXfd9R47ywZs2aKUkqKyvTueeeK59v7Eq/r7zyit544w1J0vr1G/TGuu2qnLlCtfO/KZfb3D1SgFxAUIB3sCxL+cX1yi+uVzIxpNFYv9a129r8+g+lzLB+88RrcrnGjrjv7x/Q0NCgZh/zaQVKzlbjGX4FwvyrHpMTQQHeg9dXIK+vQJK0aOl393p8ypEeEOBgnNgIADCCoAAAjCAoAAAjCAoAwAiCAgAwgqAAAIwgKAAAIwgKAMAIggIAMIKgAACMICgAACMICgDACIICADCCoAAAjCAoAAAjCAoAwAiCAgAwgqAAAIwgKAAAIwgKAMAIggIAMIKgAACMICgAACMICgDACIICADCCoAAAjCAoAAAjCAoAwAiCAgAwgqAAAIwgKAAAIwgKAMAIggIAMIKgAACMICgAACMICgDACIICADCCoAAAjCAoAAAjCAoAwAiCAgAwgqAAAIwgKAAAIwgKAMAIT7YHADiLPf5/lmzJsvfxFEu2rL/5grX3c4BJiKAAsuV1x+X3ROX3ROVxJ+TzxOVxx+V1J+SybI2FxlLGtpRM+5RM+5VM+ZVM+5RIBRVPBZVM+0VcMJkRFEwytizZcrtS8nsjKgr1KD/QL78nJq87Lo87IZeVkXUAXbBtKWO7lEz7lEr7FU8FNBwr1sBoueKpkNIZz66ZDJHB5EBQMEnYcllpFQT6VBTuUUGwV2HfkKxdu7QOJCDvZFmS28rI7YpJ3pjC9qBKwl2qLXlLo4kCDUVK1R8p13CsRBnbLcKCiY6gYILLyO+JqTC4UxUFOxTyD8vjSh5UQPZn9zYty1Z+YFB5/kFVFOzQaKJA3UM1GoqWKZ4KiGNhMFERFExAY7MOrzuuioIdqshvVdA3IungZiIHy7IkryepQnevCoO9iiTy1DM0Td3DNbvWWyRmLZhICAommLEF9pJwh6qKmhX0jexaVM+e3REL+0cULGtSWUGrOgdmqG+0Ssm0T0QFEwVBwQQxFo38QJ9qireoKNyT9ZDsi8uylecf1qyK9Soe7VZrX51G4sW7HiUsyG0EBROAPb57a2rRNnndiSO6a+tguCxbJeEu5Qf61T4wS11D05TisGPkOIKCHGcr4B3VjLKNKg71yOXKZHtAB8yyJJ8nodqSTcrzD6i5d55iyZCICnIVQUEOs1UY7NGMso0K+4cdPyt5Ny5XRqV5nQp4I9q+c54Go2UiKshFHL+InGQpo/L8VtVVrM3pmOxmWVLYP6TZFWtVltcqS7kz0wJ2Y4aCnGMpo/KCHZpZtlFuVyrnY7KbZUkBb0SzK9bLZWXUMzxNNv/mQw7htxU5xVJGFQUtml7aNKFisptlSW5XStPLmlRR0MJMBTmFoCBHjF2gsTSvQzPK3pTP4/wjuQ7W7sX66WVNKsnr0O73DjgdQUHOKAz2aHrZ2MxkMvC4kppe2qTC4M5sDwU4IAQFOcCW3xPR9LImBbyRCTszeSfLkoK+iKaXvim/JypmKXA6ggKHs+VxJTSzbIPy/IPZHkxW5AUGNaNsgzyuhIgKnIygwPHKC1pVHO6ZNDOTd7IsqSTcrfL8tmwPBXhPBAUOZivP36/qoq05dQb84eByZVRdvFVh/4CYpcCpCAocy+NKqKZki3yeeLaH4gg+T0zTSjbL40pmeyjAPhEUOJSt4nC3SsJdk3ZX1zvt3vVVFOoWsxQ4EUGBI3ndcVUVvZ3tYTiQraqit+V1M2uD8xAUOJCtsrx2hX25f40u03Zf86t0/IRHwDkIChzH645rSmHzpF+IfzduV0aVhc3yuBPZHgqwB4ICh7FVEOxVaNc94LFvId+wCgO9YpYCJyEocBSXlVZFfmu2h5ETygta5bLS2R4GMI6gwEFs5fkHlBcYZO1kPyxLygsMKOwfFLMUOAVBgaMUhno5gukA+dxxLhwJRyEocAyXlVZhaPJeYuX9siypKLRTLouDF+AMBAWO4fNElecbyvYwckrYPyifJ5LtYQCSCAocpCi0UxaHCr8vLldGRez2gkMQFDiErTz/oCwWmN8XS7bCARbm4QwEBY7gcSXkn0Q3zzLFsqSAN7LrXilAdhEUOILXE5ffE8v2MHKS3xOTl7Pm4QAEBQ5gy+tOyEdQDorPE9t1qDW7vZBdBAWO4HElOOv7ILmstDxu7pGC7CMocASfJ876yUGyLHEyKByBoMARvG52dx0KdhfCCQgKHMHLLptDwqI8nICgwBG4fMihsSwW5JF9BAXOwAfiIeGEUDgBQYEz2KzIHwqbnx8cgKDAETI2v4qHgp8fnIDfQjhCIu3P9hByWpKfHxyAoMARkik+EA8FQYYTEBQ4QjLtl8268kGxbYIMZyAocIRU2qd0xpPtYeSkdMajVMab7WEABAVOYCmZ9imRCmR7IDkpkQrsWkPhSC9kF0GBIyTSfsUJykGJp4IsysMRCAocIZ3xKpYMsY7yPtm2FEuG2F0IRyAocAhLw7ES2ey2eV9sWRqOFovdXXACggLHGIqWKJNxZ3sYOSWd8WgwVprtYQCSCAocJJEOaChWnO1h5JThaDHrJ3AMggLHsG2XBiNlrKMcINuWBiJlsrnsChyC30Q4ymC0VPFUMNvDyAnxVFBD7O6CgxAUOIilSLxAQ9FiZin7Ydtja06ReL5YkIdTEBQ4ii23eoZrONprP2xZ6h6qkS0OYoBzEBQ4znCseNehsHg3w9FijcT5GcFZCAocJ53xqmuoVumMm11f72DbUirtVtdgLSczwnEIChzIUt9IpYaYpezTUKxEvaOVYu0ETkNQ4Ehp26uOgZncifAdMrZr18+FqwvDefjbCscajJapZ7ia3V672LbUM1SjoSiHCsOZCAocK2O71dZfp2ginO2hOEI0kae2/tnK2BzZBWciKHAwS7FkWDv66yf1Ar1tS+mMWzv66hVLhcXaCZyKoMDx+kYq1TU4bdKem2LLUudgrfpGK7M9FOA9ERQ4nKWM7dWO/noNRkon3SzFtqXBSJla++qVsT1idgInIyjICam0X9t3ztNIvHDSRMW2pZFYobbvnKdUxpft4QD7RVCQIyxFEgXavrNBiVRgwkfFtsfuFb+9d54iCa7XhdxAUJBDLA1Fy7Sl+5gJfbvg3bf13dK1cNchwsQEuYGgIMdYGohUaFvP0YpPwJmKbY9dln5bz9EaiJaLmCCXEBTkoLGobOpsnFBrKrYtjcQLtamzUQORChET5BqCghxlaThWqi1di9Q/WqGMndsfvhnbUt9ohTZ3LdJwrETEBLmIoCCHWYok8rW5a5E6B6bn5MmPu09a7BiYri1djYqyAI8cxvWvkeMspTI+Nfc2aDBaqtrSTQr5RmRZzi+LbVsajedpR99cDUTKd11ShZggdxEUTACWMrZHfaNViiQKNLVomyoKdshlZcYeddBn9O4ZVMZ2q3uoRu0DsxRLcjkVTAwEBRPI2LW/tu+cr96RKlUVva3CYK887lS2BzYunfFoIFKmjsGZGo4Vy7ZdIiaYKAgKJhhLGdutwWi5RuJFKgr2qLJou/ID/XJZmazMVmx77D4mw9ESdQ5O10CkXGnuZ4IJiKBgwkpnvOodrVJ/pEJh/6DK81tVFOpVwDt6RMJi21I0GdZgZOy+LqPxQtZJMKERFExwY+srw7ESjcSKFPBGlB/oU1G4RwWBPnncKbmstJHAjM1E3EqlvRqKFWtgtFzDsZKxs/rFri1MfAQFk4QlW25Fk3mKJvPUPVwrrzuu/ECf8gKDCnpHFfBGFPCOyu1KHVBgbFtKZTyKJ8OKJkOKJcMaiRVqOFaiZNq/x2sDkwFBwSTz1w/3ZDqgvtGp6hutkstKyeNOye1KyuNKyeuOyeeJy+uO7zpazNbYbMelZNqvRMqvZDqgVMajdNqrVMbD5eUx6REUYNc9VxIpr6TAQX0/AIICvANxAA4Wl14BABhBUAAARhAUAIARBAUAYARBAQAYQVAAAEYQFACAEQQFAGAEQQEAGEFQAABGEBQAgBEEBQBgBEEBABhBUAAARhAUAIARBAUAYARBAQAYQVAAAEZwC2C8b4sXFaq0yJvtYeAwq58ZyvYQkGMs27btbA8CAJD72OUFADCCoAAAjCAoAAAjCAoAwAiCAgAwgqAAAIwgKAAAIwgKAMAIggIAMIKgAACMICgAACMICgDACIICADCCoAAAjCAoAAAjCAoAwAiCAgAwgqAAAIz4/9yrdGx3dywGAAAAAElFTkSuQmCC",
      "text/plain": [
       "<Figure size 500x500 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "frames = []\n",
    "\n",
    "# reset environment for agent to be in start location\n",
    "o, env = env.reset(keys[1:])\n",
    "frames.append(env.render(mode=\"rgb_array\"))\n",
    "\n",
    "# append frame for each action \n",
    "# actions = [[3,0], [0,0], [4,0], [2,0], [4,0], [1,0]] # manual actions - without agent's generative model\n",
    "actions = info[\"action\"][0] # from agent's generative model\n",
    "for action in actions:\n",
    "    o, env = env.step(keys[1:], jnp.array([action] * batch_size))\n",
    "    frames.append(env.render(mode=\"rgb_array\"))\n",
    "\n",
    "# convert to numpy array\n",
    "frames = np.array(frames)\n",
    "\n",
    "# creating figure for animation\n",
    "fig, ax = plt.subplots(figsize=(5, 5))\n",
    "ax.axis('off')\n",
    "\n",
    "def animate(frame):\n",
    "    ax.clear()\n",
    "    ax.axis('off')\n",
    "    ax.imshow(frames[frame])\n",
    "    return ax,\n",
    "\n",
    "# displaying animation\n",
    "anim = FuncAnimation(fig, animate, frames=len(frames), interval=1000)\n",
    "HTML(anim.to_jshtml())\n",
    "\n",
    "# save as gif\n",
    "anim.save('tmaze.gif', writer=PillowWriter(fps=1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
