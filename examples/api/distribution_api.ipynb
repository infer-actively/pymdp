{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Named Distributions API\n",
    "\n",
    "In this notebook we'll give some example uses of the named distribution api\n",
    "designed for easier querying and construction of complicated A and B tensors.\n",
    "\n",
    "The distribution objects allow for giving semantically sensible names to axes\n",
    "and indices within a tensor. These can be made interactively in code or an \n",
    "entire set of A and B tensors can be compiled from a structured model\n",
    "description.\n",
    "\n",
    "Below is an example of how to build a distribution from code for a model\n",
    "conisting of a single observation modality \"observation\" consiting of the\n",
    "possible observations {A, B, C, D}. A hidden state \"state\" consisting of the\n",
    "values {A, B, C, D} and controls \"control\" {up, down}."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import jax.tree_util as jtu\n",
    "from jax import numpy as jnp\n",
    "\n",
    "np.set_printoptions(precision=2, suppress=True)\n",
    "\n",
    "from pymdp.jax.agent import Agent\n",
    "from pymdp.jax.distribution import Distribution, compile_model\n",
    "\n",
    "observations = [\"A\", \"B\", \"C\", \"D\"]\n",
    "states = [\"A\", \"B\", \"C\", \"D\"]\n",
    "controls = [\"up\", \"down\"]\n",
    "\n",
    "data = np.zeros((len(observations), len(states)))\n",
    "A = Distribution({\"observations\": observations}, {\"states\": states}, data)\n",
    "\n",
    "A[\"A\", \"A\"] = 1.0 \n",
    "A[\"B\", \"B\"] = 1.0\n",
    "A[\"C\", \"C\"] = 1.0\n",
    "A[\"D\", \"D\"] = 1.0\n",
    "\n",
    "data = np.zeros((len(states), len(states), len(controls)))\n",
    "B = Distribution({\"states\": states}, {\"states\": states, \"controls\": controls}, data)\n",
    "\n",
    "B[\"B\", \"A\", \"up\"] = 1.0\n",
    "B[\"C\", \"B\", \"up\"] = 1.0\n",
    "B[\"D\", \"C\", \"up\"] = 1.0\n",
    "B[\"D\", \"D\", \"up\"] = 1.0\n",
    "\n",
    "B[\"A\", \"A\", \"down\"] = 1.0\n",
    "B[\"A\", \"B\", \"down\"] = 1.0\n",
    "B[\"B\", \"C\", \"down\"] = 1.0\n",
    "B[\"C\", \"D\", \"down\"] = 1.0\n",
    "\n",
    "\n",
    "C = Distribution({\"observations\": observations})\n",
    "C[\"D\"] = 1.0\n",
    "\n",
    "D = Distribution({\"states\": states})\n",
    "D[\"A\"] = 1.0\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now we can use these A,B,C tensors to create an agent, and infer states and actions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "goal state: D\n",
      "initial state: A\n",
      "action taken: up\n"
     ]
    }
   ],
   "source": [
    "agent = Agent([A], [B], [C], [D], apply_batch=True)\n",
    "print(f\"goal state: {states[jnp.argmax(agent.C[0])]}\")\n",
    "\n",
    "# infer state given action and observation\n",
    "action = jnp.array([1])\n",
    "action = jnp.broadcast_to(action, (1, 1))\n",
    "\n",
    "observation = jnp.array([0])\n",
    "observation = jnp.broadcast_to(observation, (1, 1))\n",
    "\n",
    "# qs needs a time dimension for infer_empirical_prior, so expand dims of D\n",
    "qs_init = jtu.tree_map(lambda x: jnp.expand_dims(x, 0), agent.D)\n",
    "prior, _ = agent.infer_empirical_prior(action, qs_init)\n",
    "qs = agent.infer_states([observation], None, prior, None)\n",
    "print(f\"initial state: {states[jnp.argmax(qs[0])]}\")\n",
    "\n",
    "q_pi, G = agent.infer_policies(qs)\n",
    "action = agent.sample_action(q_pi)\n",
    "print(f\"action taken: {controls[action[0][0]]}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Using configs\n",
    "Alternatively you can use a model description to just generate the shape of the\n",
    "A's and the B's in one go. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "goal state: D\n",
      "initial state: A\n",
      "action taken: up\n"
     ]
    }
   ],
   "source": [
    "model = {\n",
    "    \"observations\": {\n",
    "        \"o1\": {\"elements\": [\"A\", \"B\", \"C\", \"D\"], \"depends_on\": [\"s1\"]},\n",
    "    },\n",
    "    \"controls\": {\"c1\": {\"elements\": [\"up\", \"down\"]}},\n",
    "    \"states\": {\n",
    "        \"s1\": {\"elements\": [\"A\", \"B\", \"C\", \"D\"], \"depends_on\": [\"s1\"], \"controlled_by\": [\"c1\"]},\n",
    "    },\n",
    "}\n",
    "\n",
    "As, Bs = compile_model(model)\n",
    "\n",
    "As[0][\"A\", \"A\"] = 1.0\n",
    "As[0][\"B\", \"B\"] = 1.0\n",
    "As[0][\"C\", \"C\"] = 1.0\n",
    "As[0][\"D\", \"D\"] = 1.0\n",
    "\n",
    "Bs[0][\"B\", \"A\", \"up\"] = 1.0\n",
    "Bs[0][\"C\", \"B\", \"up\"] = 1.0\n",
    "Bs[0][\"D\", \"C\", \"up\"] = 1.0\n",
    "Bs[0][\"D\", \"D\", \"up\"] = 1.0\n",
    "\n",
    "Bs[0][\"A\", \"A\", \"down\"] = 1.0\n",
    "Bs[0][\"A\", \"B\", \"down\"] = 1.0\n",
    "Bs[0][\"B\", \"C\", \"down\"] = 1.0\n",
    "Bs[0][\"C\", \"D\", \"down\"] = 1.0\n",
    "\n",
    "Cs = [jnp.array([0.0, 0.0, 0.0, 1.0])]\n",
    "agent = Agent(As, Bs, Cs, apply_batch=True)\n",
    "print(f\"goal state: {states[jnp.argmax(Cs[0])]}\")\n",
    "\n",
    "prior, _ = agent.infer_empirical_prior(action, qs_init)\n",
    "qs = agent.infer_states([observation], None, prior, None)\n",
    "print(f\"initial state: {states[jnp.argmax(qs[0])]}\")\n",
    "\n",
    "q_pi, G = agent.infer_policies(qs)\n",
    "action = agent.sample_action(q_pi)\n",
    "print(f\"action taken: {controls[action[0][0]]}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = {\n",
    "    \"observations\": {\n",
    "        \"temperature\": {\"elements\": [\"low\", \"medium\", \"high\", \"very high\"], \"depends_on\": [\"operating_state\"]},\n",
    "        \"humidity\": {\"elements\": [\"low\", \"medium\", \"high\", \"very high\"], \"depends_on\": [\"maintenance_state\"]},\n",
    "        \"pressure\": {\"elements\": [\"low\", \"medium\", \"high\", \"very high\"], \"depends_on\": [\"power_state\"]},\n",
    "        \"vibration\": {\n",
    "            \"elements\": [\"none\", \"low\", \"medium\", \"high\"],\n",
    "            \"depends_on\": [\"operating_state\", \"maintenance_state\"],\n",
    "        },\n",
    "    },\n",
    "    \"controls\": {\n",
    "        \"temperature_control\": {\"elements\": [\"off\", \"low\", \"medium\", \"high\"]},\n",
    "        \"humidity_control\": {\"elements\": [\"off\", \"low\", \"medium\", \"high\"]},\n",
    "        \"pressure_control\": {\"elements\": [\"off\", \"low\", \"medium\", \"high\"]},\n",
    "    },\n",
    "    \"states\": {\n",
    "        \"operating_state\": {\n",
    "            \"elements\": [\"idle\", \"running\", \"overload\"],\n",
    "            \"depends_on\": [\"operating_state\"],\n",
    "            \"controlled_by\": [\"temperature_control\"],\n",
    "        },\n",
    "        \"maintenance_state\": {\n",
    "            \"elements\": [\"regular\", \"alert\", \"critical\"],\n",
    "            \"depends_on\": [\"maintenance_state\"],\n",
    "            \"controlled_by\": [\"humidity_control\"],\n",
    "        },\n",
    "        \"power_state\": {\n",
    "            \"elements\": [\"low\", \"normal\", \"high\"],\n",
    "            \"depends_on\": [\"power_state\"],\n",
    "            \"controlled_by\": [\"pressure_control\"],\n",
    "        },\n",
    "    },\n",
    "}\n",
    "\n",
    "As, Bs = compile_model(model)\n",
    "\n",
    "As[0][\"low\", \"idle\"] = 1.0\n",
    "As[0][\"medium\", \"running\"] = 1.0\n",
    "As[0][\"low\", \"overload\"] = 1.0\n",
    "\n",
    "As[1][\"low\", \"regular\"] = 1.0\n",
    "As[1][\"low\", \"alert\"] = 1.0\n",
    "As[1][\"high\", \"critical\"] = 1.0\n",
    "\n",
    "As[2][\"low\", \"low\"] = 1.0\n",
    "As[2][\"medium\", \"low\"] = 1.0\n",
    "As[2][\"high\", \"high\"] = 1.0\n",
    "\n",
    "Bs[0][\"running\", \"idle\", \"low\"] = 1.0\n",
    "Bs[0][\"overload\", \"running\", \"medium\"] = 1.0\n",
    "Bs[0][\"overload\", \"overload\", \"high\"] = 1.0\n",
    "\n",
    "Bs[0][\"idle\", \"idle\", \"off\"] = 1.0\n",
    "Bs[0][\"idle\", \"running\", \"off\"] = 1.0\n",
    "Bs[0][\"running\", \"overload\", \"off\"] = 1.0\n",
    "Bs[0][\"running\", \"running\", \"off\"] = 1.0\n",
    "\n",
    "Bs[1][\"alert\", \"regular\", \"low\"] = 1.0\n",
    "Bs[1][\"critical\", \"alert\", \"medium\"] = 1.0\n",
    "Bs[1][\"critical\", \"critical\", \"high\"] = 1.0\n",
    "\n",
    "Bs[1][\"regular\", \"regular\", \"off\"] = 1.0\n",
    "Bs[1][\"regular\", \"alert\", \"off\"] = 1.0\n",
    "Bs[1][\"alert\", \"critical\", \"off\"] = 1.0\n",
    "Bs[1][\"alert\", \"alert\", \"off\"] = 1.0\n",
    "\n",
    "Bs[2][\"normal\", \"low\", \"low\"] = 1.0\n",
    "Bs[2][\"high\", \"normal\", \"medium\"] = 1.0\n",
    "Bs[2][\"high\", \"high\", \"high\"] = 1.0\n",
    "\n",
    "Bs[2][\"low\", \"low\", \"off\"] = 1.0\n",
    "Bs[2][\"low\", \"normal\", \"off\"] = 1.0\n",
    "Bs[2][\"normal\", \"high\", \"off\"] = 1.0\n",
    "Bs[2][\"normal\", \"normal\", \"off\"] = 1.0\n",
    "\n",
    "agent = Agent(As, Bs, apply_batch=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "pymdp",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
