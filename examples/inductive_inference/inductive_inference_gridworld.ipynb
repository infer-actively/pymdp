{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import jax.tree_util as jtu\n",
    "from jax import numpy as jnp, random as jr\n",
    "from jax import nn, vmap\n",
    "from equinox import tree_at\n",
    "\n",
    "import numpy as np\n",
    "\n",
    "from pymdp.envs import GridWorld, rollout\n",
    "from pymdp import control\n",
    "from pymdp.agent import Agent\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Grid world generative model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# size of the grid world\n",
    "grid_shape = (7, 7)\n",
    "\n",
    "# number of agents\n",
    "batch_size = 5\n",
    "\n",
    "# start in the middle of the grid\n",
    "env = GridWorld(shape=grid_shape, initial_position=(3,3), include_stay=False, batch_size=batch_size)\n",
    "\n",
    "desired_state = (6,6)  # bottom right corner\n",
    "# get linear index of desired state\n",
    "desired_state_id = env.coords_to_index(shape=grid_shape, coord=desired_state)\n",
    "\n",
    "# create helpful num_obs and num_states lists (lists of observation dimensions per modality, and state dimensions per factor, respectively)\n",
    "num_obs = [a.shape[1] for a in env.params['A']]\n",
    "num_states = [b.shape[-2] for b in env.params['B']]\n",
    "num_controls = [b.shape[-1] for b in env.params['B']]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Planning and inductive inference parameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "planning_horizon, inductive_threshold = 1, 0.1\n",
    "inductive_depth = 7\n",
    "policy_matrix = control.construct_policies(num_states, num_controls, policy_len=planning_horizon)\n",
    "\n",
    "# inductive planning goal states\n",
    "H = [jnp.broadcast_to(nn.one_hot(desired_state_id, num_states[0]), (batch_size, num_states[0]))] # list of factor-specific goal vectors (shape of each is (n_batches, num_states[f]))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Initialize an `Agent()`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# create agent, using generative process parameters from the environment to initialize the generative model\n",
    "A = env.params['A']\n",
    "B = env.params['B']\n",
    "C = [jnp.repeat(nn.one_hot(desired_state_id, num_states[0])[None, :], batch_size, axis=0)] # preferred outcomes (shape of each is (n_batches, num_obs[f]))\n",
    "D = env.params['D']\n",
    "agent = Agent(A, B, C, D, batch_size=batch_size, policies=policy_matrix, policy_len=planning_horizon, \n",
    "            inductive_depth=inductive_depth, inductive_threshold=inductive_threshold,\n",
    "            H=H, use_utility=True, use_states_info_gain=False, use_param_info_gain=False, use_inductive=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Run active inference"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "T = 7 \n",
    "last, info, env = rollout(agent, env, num_timesteps=T, rng_key = jr.PRNGKey(0))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Grid position for agent 2 at time 0: (3, 3)\n",
      "Grid position for agent 2 at time 1: (3, 4)\n",
      "Grid position for agent 2 at time 2: (3, 5)\n",
      "Grid position for agent 2 at time 3: (3, 6)\n",
      "Grid position for agent 2 at time 4: (4, 6)\n",
      "Grid position for agent 2 at time 5: (5, 6)\n",
      "Grid position for agent 2 at time 6: (6, 6)\n"
     ]
    }
   ],
   "source": [
    "agent_id_to_track = 1\n",
    "for t in range(T):\n",
    "    state_time_t = env.index_to_coords(shape=grid_shape, idx=info['env'].state[0][agent_id_to_track, t])\n",
    "    print(f\"Grid position for agent {agent_id_to_track+1} at time {t}: {state_time_t}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Now the agent starts further from the goal and thus need more timesteps to reach it"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# size of the grid world\n",
    "grid_shape = (7, 7)\n",
    "\n",
    "# number of agents\n",
    "batch_size = 5\n",
    "\n",
    "upper_left_initial_state = env.coords_to_index(shape=grid_shape, coord=(0,0))\n",
    "initial_state_prior = [jnp.repeat(nn.one_hot(upper_left_initial_state, num_states[0])[None, :], batch_size, axis=0)]\n",
    "env = tree_at(lambda x: x.params['D'], env, initial_state_prior)\n",
    "\n",
    "# start in the upper left corner this time\n",
    "_, env = env.reset(jr.split(jr.PRNGKey(0), batch_size))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Increase inductive planning depth in order to compute the needed inductive planning matrix "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "planning_horizon, inductive_threshold = 1, 0.1\n",
    "inductive_depth = 14\n",
    "policy_matrix = control.construct_policies(num_states, num_controls, policy_len=planning_horizon)\n",
    "\n",
    "# inductive planning goal states\n",
    "H = [jnp.broadcast_to(nn.one_hot(desired_state_id, num_states[0]), (batch_size, num_states[0]))] # list of factor-specific goal vectors (shape of each is (n_batches, num_states[f]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# create agent, using generative process parameters from the environment to initialize the generative model\n",
    "A = env.params['A']\n",
    "B = env.params['B']\n",
    "C = [jnp.repeat(nn.one_hot(desired_state_id, num_states[0])[None, :], batch_size, axis=0)] # preferred outcomes (shape of each is (n_batches, num_obs[f]))\n",
    "D = [jnp.repeat(nn.one_hot(upper_left_initial_state, num_states[0])[None, :], batch_size, axis=0)] # need to do this since the D of the environment won't match the env state if you reset to a different state\n",
    "agent = Agent(A, B, C, D, batch_size=batch_size, policies=policy_matrix, policy_len=planning_horizon, \n",
    "            inductive_depth=inductive_depth, inductive_threshold=inductive_threshold,\n",
    "            H=H, use_utility=True, use_states_info_gain=False, use_param_info_gain=False, use_inductive=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Run active inference"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "T = 14\n",
    "last, info, env = rollout(agent, env, num_timesteps=T, rng_key = jr.PRNGKey(0))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Grid position for agent 2 at time 0: (0, 0)\n",
      "Grid position for agent 2 at time 1: (0, 1)\n",
      "Grid position for agent 2 at time 2: (0, 2)\n",
      "Grid position for agent 2 at time 3: (0, 3)\n",
      "Grid position for agent 2 at time 4: (0, 4)\n",
      "Grid position for agent 2 at time 5: (0, 5)\n",
      "Grid position for agent 2 at time 6: (0, 6)\n",
      "Grid position for agent 2 at time 7: (1, 6)\n",
      "Grid position for agent 2 at time 8: (2, 6)\n",
      "Grid position for agent 2 at time 9: (3, 6)\n",
      "Grid position for agent 2 at time 10: (4, 6)\n",
      "Grid position for agent 2 at time 11: (5, 6)\n",
      "Grid position for agent 2 at time 12: (6, 6)\n",
      "Grid position for agent 2 at time 13: (6, 6)\n"
     ]
    }
   ],
   "source": [
    "agent_id_to_track = 1\n",
    "for t in range(T):\n",
    "    state_time_t = env.index_to_coords(shape=grid_shape, idx=info['env'].state[0][agent_id_to_track, t])\n",
    "    print(f\"Grid position for agent {agent_id_to_track+1} at time {t}: {state_time_t}\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "pymdp_dev_env",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
