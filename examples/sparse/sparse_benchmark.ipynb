{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Sparse Array Benchmarking"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import jax.numpy as jnp\n",
    "from jax import tree_util as jtu, nn, vmap, lax\n",
    "from jax.experimental import sparse\n",
    "from pymdp.jax.agent import Agent\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import time\n",
    "import sys\n",
    "\n",
    "from pymdp.jax.inference import smoothing_ovf\n",
    "import numpy as np\n",
    "import jax.profiler \n",
    "\n",
    "import tracemalloc\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def sizeof(x):\n",
    "    return np.prod(x.shape)\n",
    "\n",
    "\n",
    "def sizeof_sparse(x):\n",
    "    return np.prod(x.data.shape) + np.prod(x.indices.shape)\n",
    "\n",
    "\n",
    "def get_matrices(n_batch, num_obs, n_states):\n",
    "\n",
    "    A_1 = jnp.ones((num_obs[0], n_states[0]))\n",
    "    A_1 = A_1.at[-1, :-1].set(0)\n",
    "    A_2 = jnp.ones((num_obs[0], n_states[1]))\n",
    "    A_2 = A_2.at[-1, 1:].set(0)\n",
    "\n",
    "    A_tensor = A_1[..., None] * A_2[:, None]\n",
    "    A_tensor /= A_tensor.sum(0)\n",
    "\n",
    "    A = [jnp.broadcast_to(A_tensor, (n_batch, *A_tensor.shape))]\n",
    "\n",
    "    # create two transition matrices, one for each state factor\n",
    "    B_1 = jnp.eye(n_states[0])\n",
    "    B_1 = B_1.at[:, 1:].set(B_1[:, :-1])\n",
    "    B_1 = B_1.at[:, 0].set(0)\n",
    "    B_1 = B_1.at[-1, 0].set(1)\n",
    "    B_1 = jnp.broadcast_to(B_1, (n_batch, n_states[0], n_states[0]))\n",
    "\n",
    "    B_2 = jnp.eye(n_states[1])\n",
    "    B_2 = B_2.at[:, 1:].set(B_2[:, :-1])\n",
    "    B_2 = B_2.at[:, 0].set(0)\n",
    "    B_2 = B_2.at[-1, 0].set(1)\n",
    "    B_2 = jnp.broadcast_to(B_2, (n_batch, n_states[1], n_states[1]))\n",
    "\n",
    "    B = [B_1[..., None], B_2[..., None]]\n",
    "    C = [jnp.zeros((n_batch, num_obs[0]))]  # flat preferences\n",
    "    D = [jnp.ones((n_batch, n_states[0])) / n_states[0], jnp.ones((n_batch, n_states[1])) / n_states[1]]  # flat prior\n",
    "    E = jnp.ones((n_batch, 1))\n",
    "\n",
    "    return A, B, C, D, E"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def profile(fun, *args): \n",
    "    tracemalloc.start()\n",
    "    tracemalloc.reset_peak()\n",
    "    bt = time.time()\n",
    "    res = fun(*args)\n",
    "    et = time.time()\n",
    "    size, peak = tracemalloc.get_traced_memory()\n",
    "\n",
    "    stats = {'time': et - bt}\n",
    "    return res, stats\n",
    "\n",
    "def experiment(n_states):\n",
    "    results = {}\n",
    "\n",
    "    n_batch = 1\n",
    "    num_obs = [2]\n",
    "\n",
    "    A, B, C, D, E = get_matrices(n_batch=n_batch, num_obs=num_obs, n_states=n_states)\n",
    "\n",
    "    # for the single modality, a sequence over time of observations (one hot vectors)\n",
    "    obs = [\n",
    "        jnp.broadcast_to(\n",
    "            jnp.array(\n",
    "                [\n",
    "                    [1.0, 0.0],  # observation 0 is ambiguous with respect state factors\n",
    "                    [1.0, 0],  # observation 0 is ambiguous with respect state factors\n",
    "                    [1.0, 0],  # observation 0 is ambiguous with respect state factors\n",
    "                    [0.0, 1.0],\n",
    "                ]\n",
    "            )[:, None],\n",
    "            (4, n_batch, num_obs[0]),\n",
    "        )\n",
    "    ]  # observation 1 provides information about exact state of both factors\n",
    "\n",
    "    agents = Agent(\n",
    "        A=A,\n",
    "        B=B,\n",
    "        C=C,\n",
    "        D=D,\n",
    "        E=E,\n",
    "        pA=None,\n",
    "        pB=None,\n",
    "        policy_len=3,\n",
    "        control_fac_idx=None,\n",
    "        policies=None,\n",
    "        gamma=16.0,\n",
    "        alpha=16.0,\n",
    "        use_utility=True,\n",
    "        onehot_obs=True,\n",
    "        action_selection=\"deterministic\",\n",
    "        sampling_mode=\"full\",\n",
    "        inference_algo=\"ovf\",\n",
    "        num_iter=16,\n",
    "        learn_A=False,\n",
    "        learn_B=False,\n",
    "        apply_batch=False\n",
    "    )\n",
    "\n",
    "    sparse_B = jtu.tree_map(lambda b: sparse.BCOO.fromdense(b, n_batch=n_batch), agents.B)\n",
    "\n",
    "\n",
    "    prior = agents.D\n",
    "    qs_hist = None\n",
    "    action_hist = []\n",
    "    for t in range(len(obs[0])):\n",
    "        first_obs = jtu.tree_map(lambda x: jnp.moveaxis(x[:t+1], 0, 1), obs)\n",
    "        beliefs = agents.infer_states(first_obs, past_actions=None, empirical_prior=prior, qs_hist=qs_hist)\n",
    "        actions = jnp.broadcast_to(agents.policies[0, 0], (n_batch, 2))\n",
    "        prior, qs_hist = agents.update_empirical_prior(actions, beliefs)\n",
    "        action_hist.append(actions)\n",
    "\n",
    "    beliefs = jtu.tree_map(lambda x, y: jnp.concatenate([x[:, None], y], 1), agents.D, beliefs)\n",
    "\n",
    "    take_first = lambda pytree: jtu.tree_map(lambda leaf: leaf[0], pytree)\n",
    "    beliefs_single = take_first(beliefs)\n",
    "\n",
    "    # ======\n",
    "    # Dense implementation\n",
    "    smoothed_beliefs_dense, run_stats = profile(\n",
    "        smoothing_ovf, *(beliefs_single, take_first(agents.B), jnp.stack(action_hist, 1)[0])\n",
    "    )\n",
    "    results.update({k+'_dense': v for k, v in run_stats.items()})\n",
    "    results[\"size_dense\"] = sum([sizeof(sB) for sB in agents.B])\n",
    "    # ======\n",
    "\n",
    "    sparse_B_single = jtu.tree_map(lambda b: sparse.BCOO.fromdense(b[0]), agents.B)\n",
    "    actions_single = jnp.stack(action_hist, 1)[0]\n",
    "\n",
    "    # ======\n",
    "    # Sparse implementation\n",
    "    smoothed_beliefs_sparse, run_stats = profile(\n",
    "        smoothing_ovf, *(beliefs_single, sparse_B_single, actions_single)\n",
    "    )\n",
    "    results.update({k+'_sparse': v for k, v in run_stats.items()})\n",
    "    results[\"size_sparse\"] = sum([sizeof_sparse(sB) for sB in sparse_B_single])\n",
    "    # ======\n",
    "\n",
    "    return results, [beliefs_single, smoothed_beliefs_dense, smoothed_beliefs_sparse]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Running the experiment and visualizing the results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "res, (beliefs, smoothed_dense, smoothed_sparse) = experiment([2, 3])\n",
    "\n",
    "fig, axes = plt.subplots(2, 3, figsize=(8, 4), sharex=True)\n",
    "\n",
    "sns.heatmap(beliefs[0].mT, ax=axes[0, 0], cbar=False, vmax=1., vmin=0., cmap='viridis')\n",
    "sns.heatmap(beliefs[1].mT, ax=axes[1, 0], cbar=False, vmax=1., vmin=0., cmap='viridis')\n",
    "\n",
    "sns.heatmap(smoothed_dense[0][0].mT, ax=axes[0, 1], cbar=False, vmax=1., vmin=0., cmap='viridis')\n",
    "sns.heatmap(smoothed_dense[0][1].mT, ax=axes[1, 1], cbar=False, vmax=1., vmin=0., cmap='viridis')\n",
    "\n",
    "sns.heatmap(smoothed_sparse[0][0].mT, ax=axes[0, 2], cbar=False, vmax=1., vmin=0., cmap='viridis')\n",
    "sns.heatmap(smoothed_sparse[0][1].mT, ax=axes[1, 2], cbar=False, vmax=1., vmin=0., cmap='viridis')\n",
    "\n",
    "axes[0, 0].set_title('Filtered beliefs')\n",
    "axes[0, 1].set_title('smoothed beliefs dense')\n",
    "axes[0, 2].set_title('smoothed beliefs sparse')\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Benchmarking runtime and memory performance"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "n_steps = 10\n",
    "\n",
    "res = []\n",
    "for i in range(1, n_steps):\n",
    "    print(f\"Step {i}\")\n",
    "    num_states = [1000 * i, 3000 * i]\n",
    "    print('\\t', num_states)\n",
    "    results, bel = experiment(num_states)\n",
    "    res += [results]\n",
    "    print('\\t', res[-1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "keys = list(set(r.replace(\"_dense\", \"\").replace(\"_sparse\", \"\") for r in res[0].keys())) \n",
    "n_plots = len(keys)\n",
    "\n",
    "fig, ax = plt.subplots(n_plots, 1, figsize=(6, 3 * n_plots))\n",
    "for i, a in enumerate(ax.flatten()):\n",
    "    k = keys[i]\n",
    "    a.plot([r[k + \"_dense\"] for r in res], label=f\"{k.replace('_', ' ').capitalize()} dense\")\n",
    "    a.plot([r[k + \"_sparse\"] for r in res], label=f\"{k} sparse\")\n",
    "    a.set_xticks(list(range(0, len(res))))\n",
    "    a.set_xticklabels([f\"[{1000*i}, {3000*i}]\" for i in range(1, n_steps)], rotation=45)\n",
    "    m = max([r[k + \"_dense\"] for r in res] + [r[k + \"_sparse\"] for r in res]) * 1.05\n",
    "    a.set_ylim([0, m])\n",
    "\n",
    "plt.tight_layout()\n",
    "[a.legend() for a in ax.flatten()]\n",
    "plt.show()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
